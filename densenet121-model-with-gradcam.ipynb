{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import libraries","metadata":{"id":"xrcvuvbLKtTB"}},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport subprocess\nimport cv2\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom collections import OrderedDict\n\nimport scipy\nimport scipy.ndimage as ndimage\nimport scipy.ndimage.filters as filters\nfrom scipy.ndimage import binary_dilation\nimport matplotlib.patches as patches\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nfrom torch.nn import functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom sklearn.metrics import roc_auc_score\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"id":"7mE3R8lnIR2F","execution":{"iopub.status.busy":"2022-04-07T18:00:00.653Z","iopub.execute_input":"2022-04-07T18:00:00.653319Z","iopub.status.idle":"2022-04-07T18:00:00.664122Z","shell.execute_reply.started":"2022-04-07T18:00:00.653266Z","shell.execute_reply":"2022-04-07T18:00:00.662818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_seed= 42\nnp.random.seed(random_seed)\ntorch.manual_seed(random_seed)\ntorch.cuda.manual_seed(random_seed)\ntorch.backends.cudnn.deterministic=True\ntorch.backends.cudnn.benchmark = True\nbatch_size = 64\nvalidation_split = .34\nshuffle_dataset = True","metadata":{"id":"9EqJaM-3AecT","execution":{"iopub.status.busy":"2022-04-07T18:00:00.817077Z","iopub.execute_input":"2022-04-07T18:00:00.81734Z","iopub.status.idle":"2022-04-07T18:00:00.826632Z","shell.execute_reply.started":"2022-04-07T18:00:00.817313Z","shell.execute_reply":"2022-04-07T18:00:00.825318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download Dataset","metadata":{"id":"NcWbEaKDK0Td"}},{"cell_type":"code","source":"def run_cmd(cmd, stderr=subprocess.STDOUT):\n    out = None\n    try:\n        out = subprocess.check_output(\n            [cmd], \n            shell=True,\n            stderr=subprocess.STDOUT, \n            universal_newlines=True,\n        )\n    except subprocess.CalledProcessError as e:\n        print(f'ERROR {e.returncode}: {cmd}\\n\\t{e.output}', flush=True, file=sys.stderr)\n        raise e\n    return out","metadata":{"id":"CAviEL72KU0h","execution":{"iopub.status.busy":"2022-04-07T18:00:00.961803Z","iopub.execute_input":"2022-04-07T18:00:00.962057Z","iopub.status.idle":"2022-04-07T18:00:00.968907Z","shell.execute_reply.started":"2022-04-07T18:00:00.962002Z","shell.execute_reply":"2022-04-07T18:00:00.967712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clone_data(data_root):\n    clone_uri = 'https://github.com/ieee8023/covid-chestxray-dataset.git'\n    if os.path.exists(data_root):\n        assert os.path.isdir(data_root), \\\n        f'{data_root} should be cloned from {clone_uri}'\n    else:\n        print(\n            'Cloning the covid chestxray dataset. It may take a while\\n...\\n', \n            flush=True\n        )\n        run_cmd(f'git clone {clone_uri} {data_root}')","metadata":{"id":"Py4qaHqAKJjF","execution":{"iopub.status.busy":"2022-04-07T18:00:01.128711Z","iopub.execute_input":"2022-04-07T18:00:01.128981Z","iopub.status.idle":"2022-04-07T18:00:01.135574Z","shell.execute_reply.started":"2022-04-07T18:00:01.12894Z","shell.execute_reply":"2022-04-07T18:00:01.134296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_root = \"./data\"\nmgpath=f'{data_root}/images',\ncsvpath=f'{data_root}/metadata.csv',","metadata":{"id":"eshUYKBIKLNK","execution":{"iopub.status.busy":"2022-04-07T18:00:01.274169Z","iopub.execute_input":"2022-04-07T18:00:01.274491Z","iopub.status.idle":"2022-04-07T18:00:01.280253Z","shell.execute_reply.started":"2022-04-07T18:00:01.274462Z","shell.execute_reply":"2022-04-07T18:00:01.278911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csvpath = pd.read_csv('../input/covid-chest-xray/metadata.csv')\nmgpath = '../input/covid-chest-xray/images/'","metadata":{"id":"FnqTOFKRutgo","outputId":"89fedcb7-4ba9-4005-db48-6fdeaa523647","execution":{"iopub.status.busy":"2022-04-07T18:03:13.537392Z","iopub.execute_input":"2022-04-07T18:03:13.538049Z","iopub.status.idle":"2022-04-07T18:03:13.58976Z","shell.execute_reply.started":"2022-04-07T18:03:13.538004Z","shell.execute_reply":"2022-04-07T18:03:13.588594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clone_data(data_root)","metadata":{"id":"men-IrndNYIN","execution":{"iopub.status.busy":"2022-04-07T18:00:01.61399Z","iopub.execute_input":"2022-04-07T18:00:01.614315Z","iopub.status.idle":"2022-04-07T18:00:01.619454Z","shell.execute_reply.started":"2022-04-07T18:00:01.614267Z","shell.execute_reply":"2022-04-07T18:00:01.617891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta = pd.read_csv('../input/covid-chest-xray/metadata.csv')\nmeta.head(10)","metadata":{"id":"WiUuInH0KPrt","execution":{"iopub.status.busy":"2022-04-07T18:00:01.803172Z","iopub.execute_input":"2022-04-07T18:00:01.803436Z","iopub.status.idle":"2022-04-07T18:00:01.863733Z","shell.execute_reply.started":"2022-04-07T18:00:01.80341Z","shell.execute_reply":"2022-04-07T18:00:01.861451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## View\nwe, are going to train our model against the only \"PA\" view of the lungs X-ray images.","metadata":{"id":"z__zt9bpLv4h"}},{"cell_type":"code","source":"meta['view'].value_counts(dropna=False)","metadata":{"id":"zMAa4CwGAlPe","outputId":"747f6761-8591-4dc3-934d-319871e55065","execution":{"iopub.status.busy":"2022-04-07T18:00:01.909048Z","iopub.execute_input":"2022-04-07T18:00:01.909386Z","iopub.status.idle":"2022-04-07T18:00:01.9207Z","shell.execute_reply.started":"2022-04-07T18:00:01.909333Z","shell.execute_reply":"2022-04-07T18:00:01.919433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in meta['filename']:\n    if x.split('.')[-1]=='gz':\n        meta.drop(meta.index[meta['filename']==x], \n                  inplace=True)","metadata":{"id":"0pmw_tASErZh","execution":{"iopub.status.busy":"2022-04-07T18:00:01.991627Z","iopub.execute_input":"2022-04-07T18:00:01.991935Z","iopub.status.idle":"2022-04-07T18:00:02.040884Z","shell.execute_reply.started":"2022-04-07T18:00:01.991907Z","shell.execute_reply":"2022-04-07T18:00:02.039843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta = meta[(meta['finding']=='COVID-19')\n            |(meta['finding']=='SARS')\n            |(meta['finding']=='Pneumocystis')\n            |(meta['finding']=='Streptococcus')\n            |(meta['finding']=='COVID-19, ARDS')\n            |(meta['finding']=='ARDS')]\nmeta = meta[meta['view']=='PA']","metadata":{"id":"ZyzY_IqX9uNs","execution":{"iopub.status.busy":"2022-04-07T18:00:02.18798Z","iopub.execute_input":"2022-04-07T18:00:02.188306Z","iopub.status.idle":"2022-04-07T18:00:02.204318Z","shell.execute_reply.started":"2022-04-07T18:00:02.188272Z","shell.execute_reply":"2022-04-07T18:00:02.202129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta['finding'].value_counts(dropna=False)","metadata":{"id":"TFDRP4odLrEY","outputId":"195dda46-df1e-40df-c609-e4839feba764","execution":{"iopub.status.busy":"2022-04-07T18:00:02.340406Z","iopub.execute_input":"2022-04-07T18:00:02.340682Z","iopub.status.idle":"2022-04-07T18:00:02.352374Z","shell.execute_reply.started":"2022-04-07T18:00:02.340654Z","shell.execute_reply":"2022-04-07T18:00:02.350822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Balancing the un-balanced\nAs you could clearly see that COVID affected x-ray images are ten times more in number than other classes. So in the next cell, we are going to bring down the number of images under COVID.<br>\nThe excess images of COVID that has been removed from the dataset would be used to detect the region of the lungs that has been affected by COVID-19 through heatmap visualization","metadata":{"id":"fbK1ADDCOZ9h"}},{"cell_type":"code","source":"X_train_val, X_test = train_test_split( meta[meta['finding']=='COVID-19'], test_size=0.85, random_state=random_seed)\nmeta.drop(X_test.index, inplace=True)\nmeta.reset_index(drop=True, inplace=True)","metadata":{"id":"OlUNsJIJpqXG","execution":{"iopub.status.busy":"2022-04-07T18:00:02.463455Z","iopub.execute_input":"2022-04-07T18:00:02.463691Z","iopub.status.idle":"2022-04-07T18:00:02.477809Z","shell.execute_reply.started":"2022-04-07T18:00:02.463665Z","shell.execute_reply":"2022-04-07T18:00:02.476812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"X_test\" would be used later for testing detection of affected section of lungs through heat-map","metadata":{"id":"9fckeZ1da1CC"}},{"cell_type":"code","source":"meta['finding'].value_counts(dropna=False)","metadata":{"id":"vZoGqpWgE10s","outputId":"4c20dafb-3944-4a3c-aa60-63c18ca50e0d","execution":{"iopub.status.busy":"2022-04-07T18:00:02.591467Z","iopub.execute_input":"2022-04-07T18:00:02.591787Z","iopub.status.idle":"2022-04-07T18:00:02.604184Z","shell.execute_reply.started":"2022-04-07T18:00:02.591752Z","shell.execute_reply":"2022-04-07T18:00:02.602839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_size = len(meta)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]","metadata":{"id":"SVvUqIJWLLg4","execution":{"iopub.status.busy":"2022-04-07T18:00:02.714106Z","iopub.execute_input":"2022-04-07T18:00:02.714376Z","iopub.status.idle":"2022-04-07T18:00:02.721249Z","shell.execute_reply.started":"2022-04-07T18:00:02.71435Z","shell.execute_reply":"2022-04-07T18:00:02.719968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)","metadata":{"id":"vIedQ43-TnTj","execution":{"iopub.status.busy":"2022-04-07T18:00:02.804634Z","iopub.execute_input":"2022-04-07T18:00:02.804902Z","iopub.status.idle":"2022-04-07T18:00:02.809959Z","shell.execute_reply.started":"2022-04-07T18:00:02.804874Z","shell.execute_reply":"2022-04-07T18:00:02.808563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Labels = np.array(meta['finding']).reshape(len(meta['finding']),1)\nencode = OneHotEncoder()\nencode.fit(Labels)\nlabels_enc = encode.transform(Labels).toarray()","metadata":{"id":"KJszaU1LugLy","execution":{"iopub.status.busy":"2022-04-07T18:00:02.969386Z","iopub.execute_input":"2022-04-07T18:00:02.969683Z","iopub.status.idle":"2022-04-07T18:00:02.9788Z","shell.execute_reply.started":"2022-04-07T18:00:02.96964Z","shell.execute_reply":"2022-04-07T18:00:02.977028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform=transforms.Compose([\n                              transforms.ToPILImage(),\n                              transforms.RandomCrop(224),                              \n                              transforms.ToTensor(),                                                  \n                              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                        ])","metadata":{"id":"St5lnqaHSXEf","execution":{"iopub.status.busy":"2022-04-07T18:00:03.1689Z","iopub.execute_input":"2022-04-07T18:00:03.169216Z","iopub.status.idle":"2022-04-07T18:00:03.177641Z","shell.execute_reply.started":"2022-04-07T18:00:03.169184Z","shell.execute_reply":"2022-04-07T18:00:03.176448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = [\n    'COVID-19', \n    'SARS ',\n    'Pneumocystis',       \n    'Streptococcus',      \n    'COVID-19, ARDS',     \n    'ARDS',               \n]","metadata":{"id":"jRFCYRQU9lUw","execution":{"iopub.status.busy":"2022-04-07T18:00:10.793132Z","iopub.status.idle":"2022-04-07T18:00:10.793852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChestXrayDataSet(Dataset):\n    def __init__(self,csvpath,mgpath,labels_enc,transform=None):\n        self.meta_data = pd.read_csv(csvpath)\n        self.root_dir = mgpath\n        self.labels = self.meta_data['finding']\n        self.transform = transform\n        for x in self.meta_data['filename']:\n            if x.split('.')[-1]=='gz':\n                self.meta_data.drop(self.meta_data.index[self.meta_data['filename']==x],\n                                    inplace=True)\n    \n        self.meta_data = self.meta_data[(self.meta_data['finding']=='COVID-19')\n                                        |(self.meta_data['finding']=='SARS')\n                                        |(self.meta_data['finding']=='Pneumocystis')\n                                        |(self.meta_data['finding']=='Streptococcus')\n                                        |(self.meta_data['finding']=='COVID-19, ARDS')\n                                        |(self.meta_data['finding']=='ARDS')]\n        self.meta_data = self.meta_data[self.meta_data['view']=='PA']\n        self.meta_data.drop(X_test.index, inplace=True)\n        self.meta_data.reset_index(drop=True, inplace=True)\n    \n    def __len__(self):\n        return len(self.meta_data)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img_name = os.path.join(self.root_dir,\n                                self.meta_data.loc[idx,'filename'])\n        image = Image.open(img_name).convert('RGB')\n        image = np.array(image.resize((256,256)))\n        image = image[:,:,0]\n        image = np.uint8(((np.array(image)/255).reshape(256,256,1))*255*255)\n        image = np.tile(image,3) \n        label = labels_enc[idx]\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label, idx","metadata":{"id":"S08QrgP7NBvc","execution":{"iopub.status.busy":"2022-04-07T18:03:48.626019Z","iopub.execute_input":"2022-04-07T18:03:48.626382Z","iopub.status.idle":"2022-04-07T18:03:48.645042Z","shell.execute_reply.started":"2022-04-07T18:03:48.62635Z","shell.execute_reply":"2022-04-07T18:03:48.642699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ChestXrayDataSet(csvpath[0],mgpath[0],labels_enc,transform)","metadata":{"id":"f93OrKxf5fJt","execution":{"iopub.status.busy":"2022-04-07T18:03:51.707463Z","iopub.execute_input":"2022-04-07T18:03:51.707775Z","iopub.status.idle":"2022-04-07T18:03:51.77283Z","shell.execute_reply.started":"2022-04-07T18:03:51.707729Z","shell.execute_reply":"2022-04-07T18:03:51.771319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset, \n                                           batch_size=batch_size, \n                                           sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, \n                                                batch_size=batch_size,\n                                                sampler=valid_sampler)","metadata":{"id":"nzdrgZo1ThNv","execution":{"iopub.status.busy":"2022-04-07T18:04:18.344648Z","iopub.execute_input":"2022-04-07T18:04:18.34496Z","iopub.status.idle":"2022-04-07T18:04:18.366981Z","shell.execute_reply.started":"2022-04-07T18:04:18.34493Z","shell.execute_reply":"2022-04-07T18:04:18.36565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def img_display(img):\n    img = img*0.229+0.485   # unnormalize (inp = inp*std + mean)\n    npimg = img.numpy()[0]\n  \n    return npimg","metadata":{"id":"ZVQvFv4AdiWJ","execution":{"iopub.status.busy":"2022-04-07T18:00:03.879136Z","iopub.status.idle":"2022-04-07T18:00:03.879915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the dataset","metadata":{"id":"3DLDuiWXozV7"}},{"cell_type":"code","source":"# get some random training images\ndataiter = iter(train_loader)\nimages, labels, id_ = dataiter.next()\n# Viewing data examples used for training\nfig, axis = plt.subplots(2, 4, figsize=(15, 10))\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        image, label, _ = images[i], labels[i], id_[i]\n        ax.imshow(img_display(image),cmap='gray') # add image\n        ax.set(title = f\"{meta['finding'][_.item()]}\") # add label","metadata":{"id":"ufzXtHxIeCFY","outputId":"7f4d3d52-956f-48a7-854b-c217f8b7fc87","execution":{"iopub.status.busy":"2022-04-07T18:00:03.982717Z","iopub.execute_input":"2022-04-07T18:00:03.983056Z","iopub.status.idle":"2022-04-07T18:00:04.004903Z","shell.execute_reply.started":"2022-04-07T18:00:03.983026Z","shell.execute_reply":"2022-04-07T18:00:04.003503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the model\nI have used DenseNet121, for training the model. But I would definitely suggest you to try efficient net to see If there is any possible scope for performance improvement of the model.","metadata":{"id":"0LskzeWmo5b6"}},{"cell_type":"code","source":"# construct model\nclass DenseNet121(nn.Module):\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        ).cuda()\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x","metadata":{"id":"bN8Swibhu_9F","execution":{"iopub.status.busy":"2022-04-07T18:00:04.107604Z","iopub.execute_input":"2022-04-07T18:00:04.107992Z","iopub.status.idle":"2022-04-07T18:00:04.115194Z","shell.execute_reply.started":"2022-04-07T18:00:04.10796Z","shell.execute_reply":"2022-04-07T18:00:04.114158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudnn.benchmark = True\nN_CLASSES = 6","metadata":{"id":"T9mqGfMnzsNa","execution":{"iopub.status.busy":"2022-04-07T18:00:04.130383Z","iopub.execute_input":"2022-04-07T18:00:04.130618Z","iopub.status.idle":"2022-04-07T18:00:04.135027Z","shell.execute_reply.started":"2022-04-07T18:00:04.130592Z","shell.execute_reply":"2022-04-07T18:00:04.133924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_AUCs(gt, pred):\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n","metadata":{"id":"ILvQ47_OQPCJ","execution":{"iopub.status.busy":"2022-04-07T18:00:04.293073Z","iopub.execute_input":"2022-04-07T18:00:04.293434Z","iopub.status.idle":"2022-04-07T18:00:04.300928Z","shell.execute_reply.started":"2022-04-07T18:00:04.293399Z","shell.execute_reply":"2022-04-07T18:00:04.299415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)","metadata":{"id":"6WV74WmQhhzv","outputId":"43d3d867-0cc8-49cd-eade-3a6661df2183","execution":{"iopub.status.busy":"2022-04-07T18:00:04.48432Z","iopub.execute_input":"2022-04-07T18:00:04.484658Z","iopub.status.idle":"2022-04-07T18:00:04.491392Z","shell.execute_reply.started":"2022-04-07T18:00:04.48463Z","shell.execute_reply":"2022-04-07T18:00:04.490114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize and load the model\nmodel = DenseNet121(N_CLASSES)\nmodel = model.cuda(device)","metadata":{"id":"dKcgS6hLAPSa","execution":{"iopub.status.busy":"2022-04-07T18:00:04.651048Z","iopub.execute_input":"2022-04-07T18:00:04.65152Z","iopub.status.idle":"2022-04-07T18:00:10.71798Z","shell.execute_reply.started":"2022-04-07T18:00:04.651466Z","shell.execute_reply":"2022-04-07T18:00:10.716927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(),lr=0.0007)\ncriterion = nn.BCEWithLogitsLoss()\ncriterion = criterion.cuda(device)","metadata":{"id":"Pq_PY6SqAakm","execution":{"iopub.status.busy":"2022-04-07T18:00:10.722476Z","iopub.execute_input":"2022-04-07T18:00:10.723034Z","iopub.status.idle":"2022-04-07T18:00:10.731621Z","shell.execute_reply.started":"2022-04-07T18:00:10.722976Z","shell.execute_reply":"2022-04-07T18:00:10.730637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{"id":"Mb9lw93M0VMp"}},{"cell_type":"code","source":"save_best = 0.0\nfor epoch in range(100):\n    print(\"Epoch:\",epoch)\n    running_loss = 0.0\n    for batch_idx, (data_, target_,_) in enumerate(train_loader):\n        target_ = target_.type(torch.float)\n        data_, target_ = data_.cuda(device), target_.cuda(device)\n        optimizer.zero_grad()\n        outputs = model(data_)\n        loss = criterion(outputs, target_)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n        # ======== validation ======== \n        # switch to evaluate mode\n        # initialize the ground truth and output tensor\n        with torch.no_grad():\n            model.eval()\n            gt = torch.FloatTensor()\n            gt = gt.cuda()\n            pred = torch.FloatTensor()\n            pred = pred.cuda()\n            for i, (data_t, target_t,_t) in enumerate(validation_loader):\n                target_t = target_t.type(torch.float)\n                data_t, target_t = data_t.cuda(device), target_t.cuda(device)\n                gt = torch.cat((gt, target_t), 0)\n                input_var = Variable(data_t.view(-1, 3, 224, 224).cuda())\n                output = model(input_var)\n                pred = torch.cat((pred, output.data), 0)\n            AUROCs = compute_AUCs(gt, pred)\n            AUROC_avg = np.array(AUROCs).mean()\n            print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n            if AUROC_avg>save_best:\n                save_best=AUROC_avg\n                torch.save(model.state_dict(), 'Covid_detection.pt')\n                print('Detected network improvement, saving current model')\n            for i in range(N_CLASSES):\n                print('The AUROC of {} is {}'.format(class_names[i], AUROCs[i]))\n        model.train()\n        # print statistics\n        #print('[%d] loss: %.3f' % (epoch + 1, running_loss / 715 ))\n        print(\"======================================================================\\n\")\nprint('Finished Training')","metadata":{"id":"FJkOWe9JBawI","outputId":"9bbfd456-cd7c-42c4-e2b9-c039d801e448","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-07T18:00:10.733427Z","iopub.execute_input":"2022-04-07T18:00:10.734004Z","iopub.status.idle":"2022-04-07T18:00:10.77114Z","shell.execute_reply.started":"2022-04-07T18:00:10.733852Z","shell.execute_reply":"2022-04-07T18:00:10.768867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('Covid_detection.pt'))","metadata":{"id":"oUSoSQNO6pyf","outputId":"69837b28-2660-4814-ae4e-ed63b49cd25a","execution":{"iopub.status.busy":"2022-04-07T18:00:10.772455Z","iopub.status.idle":"2022-04-07T18:00:10.773283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GradCAM( Implementation + Visualization)","metadata":{"id":"7GlJeni307El"}},{"cell_type":"code","source":"class ChestXrayDataSet_plot(Dataset):\n    def __init__(self, input_X, transform=None):\n        self.data = input_X#np.uint8(test_X*255)\n        self.transform = transform\n        self.root_dir = mgpath[0]\n        self.transform = transform\n\n    def __getitem__(self, index):\n        if torch.is_tensor(index):\n            index = index.tolist()\n        img_name = os.path.join(self.root_dir,self.data.loc[index,'filename'])\n        image = Image.open(img_name).convert('RGB')\n        image = np.array(image.resize((256,256)))\n        image = np.uint8(image*255)\n        image = self.transform(image)\n        return image\n\n    def __len__(self):\n        return len(self.data)","metadata":{"id":"sTjfw6UpfdmZ","execution":{"iopub.status.busy":"2022-04-07T18:00:10.774758Z","iopub.status.idle":"2022-04-07T18:00:10.775609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"X_test, which was extracted before would be used as a dataset for the heat-map visualization through gradcam.","metadata":{"id":"WjMXrCLatu5K"}},{"cell_type":"code","source":"X_test.reset_index(drop=True, inplace=True)\ntest_dataset = ChestXrayDataSet_plot(input_X = X_test,transform=transforms.Compose([\n                                        transforms.ToPILImage(),                                                                \n                                        transforms.ToTensor(),               \n                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                        ]))","metadata":{"id":"k89DPJvTHjlX","execution":{"iopub.status.busy":"2022-04-07T18:00:10.777216Z","iopub.status.idle":"2022-04-07T18:00:10.778126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"generate heatmap ..........\")\n# ======= Grad CAM Function =========\nclass PropagationBase(object):\n    def __init__(self, model, cuda=True):\n        self.model = model\n        self.model.eval()\n        if cuda:\n            self.model.cuda()\n        self.cuda = cuda\n        self.all_fmaps = OrderedDict()\n        self.all_grads = OrderedDict()\n        self._set_hook_func()\n        self.image = None\n\n    def _set_hook_func(self):\n        raise NotImplementedError\n\n    def _encode_one_hot(self, idx):\n        one_hot = torch.FloatTensor(1, self.preds.size()[-1]).zero_()\n        one_hot[0][idx] = 1.0\n        return one_hot.cuda() if self.cuda else one_hot\n\n    def forward(self, image):\n        self.image = image\n        self.preds = self.model.forward(self.image)\n        #self.probs = F.softmax(self.preds, dim=1)[0]\n        #self.prob, self.idx = self.preds[0].data.sort(0, True)\n\n        return self.preds.cpu().data.numpy()\n\n    def backward(self, idx):\n        self.model.zero_grad()\n        one_hot = self._encode_one_hot(idx)\n        self.preds.backward(gradient=one_hot, retain_graph=True)","metadata":{"id":"UsliY_dpMhA4","outputId":"ec50ed77-9210-49dd-c48d-3f2144dde417","execution":{"iopub.status.busy":"2022-04-07T18:00:10.779662Z","iopub.status.idle":"2022-04-07T18:00:10.780435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GradCAM(PropagationBase):\n    def _set_hook_func(self):\n        def func_f(module, input, output):\n            self.all_fmaps[id(module)] = output.data.cpu()\n    \n        def func_b(module, grad_in, grad_out):\n            self.all_grads[id(module)] = grad_out[0].cpu()\n\n        for module in self.model.named_modules():\n            module[1].register_forward_hook(func_f)\n            module[1].register_backward_hook(func_b)\n\n    def _find(self, outputs, target_layer):\n        for key, value in outputs.items():\n            for module in self.model.named_modules():\n                if id(module[1]) == key:\n                    if module[0] == target_layer:\n                        return value\n        raise ValueError('Invalid layer name: {}'.format(target_layer))\n\n    def _normalize(self, grads):\n        l2_norm = torch.sqrt(torch.mean(torch.pow(grads, 2))) + 1e-5\n        return grads / l2_norm.item() \n  \n    def _compute_grad_weights(self, grads):\n        grads = self._normalize(grads)\n        self.map_size = grads.size()[2:]\n        return nn.AvgPool2d(self.map_size)(grads)\n\n    def generate(self, target_layer):\n        fmaps = self._find(self.all_fmaps, target_layer)\n        grads = self._find(self.all_grads, target_layer)\n        weights = self._compute_grad_weights(grads)\n        gcam = torch.FloatTensor(self.map_size).zero_()\n        for fmap, weight in zip(fmaps[0], weights[0]):\n            gcam += fmap * weight.data\n    \n        gcam = F.relu(Variable(gcam))\n        gcam = gcam.data.cpu().numpy()\n        gcam -= gcam.min()\n        gcam /= gcam.max()\n        gcam = cv2.resize(gcam, (self.image.size(3), self.image.size(2)))    \n        return gcam\n    \n    def FinalImage(self, gcam, raw_image):\n        raw_image = raw_image*0.229+0.485\n        gcam = cv2.applyColorMap(np.uint8(gcam * 255.0), cv2.COLORMAP_JET)\n        gcam = np.float32(gcam) / (600)\n        gcam = gcam.astype(np.float) + raw_image.numpy()[0].astype(np.float).reshape(256,256,1)\n        gcam = gcam / gcam.max() \n  \n        return np.uint8(gcam * 255.0)","metadata":{"id":"GIRyZDse6Tzi","execution":{"iopub.status.busy":"2022-04-07T18:00:10.781915Z","iopub.status.idle":"2022-04-07T18:00:10.782624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ======== Create heatmap ===========\n\nheatmap_output = []\nimage_id = []\noutput_class = []\n\nthresholds = 0.1\ndataiter = iter(validation_loader)\nimages = dataiter.next()\ngcam = GradCAM(model=model, cuda=True)\nfor index in range(len(test_dataset)):\n    input_img = Variable((test_dataset[index]).unsqueeze(0).cuda(), requires_grad=True)\n    probs = gcam.forward(input_img)\n    activate_classes = np.where((probs > thresholds)[0]==True)[0] # get the activated class\n    for activate_class in activate_classes:\n        gcam.backward(idx=activate_class)\n        output = gcam.generate(target_layer=\"densenet121.features.denseblock4.denselayer16.conv2\")\n        #### this output is heatmap ####\n        if np.sum(np.isnan(output)) > 0:\n            print(\"fxxx nan\")\n        img = gcam.FinalImage(output, test_dataset[index])\n        heatmap_output.append(img)\n        image_id.append(index)\n        output_class.append(activate_class)\n    print(\"test \",str(index),\" finished\")","metadata":{"id":"cOP4vWIqPpvb","outputId":"0466119c-f388-4e9e-8c68-973ac4287c55","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-07T18:00:10.784145Z","iopub.status.idle":"2022-04-07T18:00:10.784929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap Visualization\nAll the images in the plot shown below are covid-19 lungs x-ray images, over which we have done heatmap visualization based on predictions done by the model.","metadata":{"id":"nz2yOo-3vFLo"}},{"cell_type":"code","source":"heatmap_output_1 = heatmap_output[:130]\nheatmap_output_2 = heatmap_output[130:]","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:00:10.786364Z","iopub.status.idle":"2022-04-07T18:00:10.787193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(26,5, figsize=(20, 125))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(heatmap_output_1[i]) # add image","metadata":{"id":"niRo2QaYxJJs","outputId":"8981cff5-fd42-4b36-d469-2a67c7bf1fe9","execution":{"iopub.status.busy":"2022-04-07T18:00:10.788629Z","iopub.status.idle":"2022-04-07T18:00:10.789501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axis = plt.subplots(11,5, figsize=(20, 50))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(heatmap_output_2[i]) # add image","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:00:10.790949Z","iopub.status.idle":"2022-04-07T18:00:10.791753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Credits\n* [COVID-XPERT: ANAI POWEREDPOPULATIONSCREENING OFCOVID-19 CASES USINGCHESTRADIOGRAPHYIMAGES](https://arxiv.org/pdf/2004.03042v1.pdf)\n* [CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rayswith Deep Learning](https://arxiv.org/pdf/1711.05225v3.pdf)\n* [Grad-CAM: Visual Explanations from Deep Networksvia Gradient-based Localization](https://arxiv.org/pdf/1610.02391.pdf)","metadata":{"id":"jm1IDZkNYqfI"}},{"cell_type":"code","source":"","metadata":{"id":"jUGTUVNn-XYM","trusted":true},"execution_count":null,"outputs":[]}]}