{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport PIL\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:43:11.293325Z","iopub.execute_input":"2022-03-22T17:43:11.293666Z","iopub.status.idle":"2022-03-22T17:43:16.610830Z","shell.execute_reply.started":"2022-03-22T17:43:11.293585Z","shell.execute_reply":"2022-03-22T17:43:16.609936Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/covidx-cxr2/train.txt', sep=\" \", header=None)\n\ntrain_df.columns=['patient id', 'filename', 'class', 'data source']\n\ntrain_df=train_df.drop(['patient id', 'data source'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:26.659844Z","iopub.execute_input":"2022-03-22T17:46:26.660211Z","iopub.status.idle":"2022-03-22T17:46:26.786363Z","shell.execute_reply.started":"2022-03-22T17:46:26.660180Z","shell.execute_reply":"2022-03-22T17:46:26.785529Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/covidx-cxr2/test.txt', sep=\" \", header=None)\ntest_df.columns=['id', 'filename', 'class', 'data source' ]\ntest_df=test_df.drop(['id', 'data source'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:30.220329Z","iopub.execute_input":"2022-03-22T17:46:30.220668Z","iopub.status.idle":"2022-03-22T17:46:30.236784Z","shell.execute_reply.started":"2022-03-22T17:46:30.220635Z","shell.execute_reply":"2022-03-22T17:46:30.235967Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df.head() # see the first 5 rows and columns of train","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:32.737764Z","iopub.execute_input":"2022-03-22T17:46:32.738139Z","iopub.status.idle":"2022-03-22T17:46:32.754598Z","shell.execute_reply.started":"2022-03-22T17:46:32.738101Z","shell.execute_reply":"2022-03-22T17:46:32.753809Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         filename     class\n0                                  ARDSSevere.png  negative\n1  acute-respiratory-distress-syndrome-ards-1.jpg  negative\n2    acute-respiratory-distress-syndrome-ards.jpg  negative\n3          ards-secondary-to-tiger-snake-bite.png  negative\n4                 pneumocystis-pneumonia-2-PA.png  negative","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ARDSSevere.png</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>acute-respiratory-distress-syndrome-ards-1.jpg</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>acute-respiratory-distress-syndrome-ards.jpg</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ards-secondary-to-tiger-snake-bite.png</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pneumocystis-pneumonia-2-PA.png</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df.head()#see the first 5 columns for test","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:35.275027Z","iopub.execute_input":"2022-03-22T17:46:35.275789Z","iopub.status.idle":"2022-03-22T17:46:35.292753Z","shell.execute_reply.started":"2022-03-22T17:46:35.275741Z","shell.execute_reply":"2022-03-22T17:46:35.291352Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                    filename     class\n0  MIDRC-RICORD-1C-419639-003251-46647-0.png  positive\n1  MIDRC-RICORD-1C-419639-001464-39871-0.png  positive\n2  MIDRC-RICORD-1C-419639-000918-78965-0.png  positive\n3  MIDRC-RICORD-1C-419639-003318-64285-0.png  positive\n4  MIDRC-RICORD-1C-419639-001015-81591-0.png  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MIDRC-RICORD-1C-419639-003251-46647-0.png</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MIDRC-RICORD-1C-419639-001464-39871-0.png</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MIDRC-RICORD-1C-419639-000918-78965-0.png</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MIDRC-RICORD-1C-419639-003318-64285-0.png</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MIDRC-RICORD-1C-419639-001015-81591-0.png</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_path = '../input/covidx-cxr2/train/'  #directory path\ntest_path = '../input/covidx-cxr2/test/'","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:37.986591Z","iopub.execute_input":"2022-03-22T17:46:37.987013Z","iopub.status.idle":"2022-03-22T17:46:37.995027Z","shell.execute_reply.started":"2022-03-22T17:46:37.986971Z","shell.execute_reply":"2022-03-22T17:46:37.994069Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:40.254415Z","iopub.execute_input":"2022-03-22T17:46:40.254745Z","iopub.status.idle":"2022-03-22T17:46:40.272473Z","shell.execute_reply.started":"2022-03-22T17:46:40.254714Z","shell.execute_reply":"2022-03-22T17:46:40.271658Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"positive    16490\nnegative    13992\nName: class, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"negative  = train_df[train_df['class']=='negative']   #negative values in class column\npositive = train_df[train_df['class']=='positive']  #positive values in class column\nfrom sklearn.utils import resample\n#majority class that  is negative, we need to downsample/decrease that class so that there is no bias\n#n_samples = 2158 means we want 2158 sample of class negative, since there are 2158 samples of class positive\ndf_majority_downsampled = resample(negative, replace = True, n_samples = 2158) \n#concatenate\ntrain_df = pd.concat([positive, df_majority_downsampled])\n\nfrom sklearn.utils import shuffle\ntrain_df = shuffle(train_df) # shuffling so that there is particular sequence","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:46.580966Z","iopub.execute_input":"2022-03-22T17:46:46.581293Z","iopub.status.idle":"2022-03-22T17:46:46.598726Z","shell.execute_reply.started":"2022-03-22T17:46:46.581264Z","shell.execute_reply":"2022-03-22T17:46:46.597791Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:50.073566Z","iopub.execute_input":"2022-03-22T17:46:50.073913Z","iopub.status.idle":"2022-03-22T17:46:50.085169Z","shell.execute_reply.started":"2022-03-22T17:46:50.073864Z","shell.execute_reply":"2022-03-22T17:46:50.084105Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"positive    16490\nnegative     2158\nName: class, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:46:56.706351Z","iopub.execute_input":"2022-03-22T17:46:56.706687Z","iopub.status.idle":"2022-03-22T17:46:56.715782Z","shell.execute_reply.started":"2022-03-22T17:46:56.706656Z","shell.execute_reply":"2022-03-22T17:46:56.714800Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n\nprint(f\"Negative and positive values of train: {train_df['class'].value_counts()}\")\nprint(f\"Negative and positive values of validation: {valid_df['class'].value_counts()}\")\nprint(f\"Negative and positive values of test: {test_df['class'].value_counts()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:47:00.403748Z","iopub.execute_input":"2022-03-22T17:47:00.404199Z","iopub.status.idle":"2022-03-22T17:47:00.417552Z","shell.execute_reply.started":"2022-03-22T17:47:00.404163Z","shell.execute_reply":"2022-03-22T17:47:00.416725Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Negative and positive values of train: positive    14848\nnegative     1935\nName: class, dtype: int64\nNegative and positive values of validation: positive    1642\nnegative     223\nName: class, dtype: int64\nNegative and positive values of test: positive    200\nnegative    200\nName: class, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, \n                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\ntest_datagen = ImageDataGenerator(rescale = 1.0/255.)\n\n#Now fit the them to get the images from directory (name of the images are given in dataframe) with augmentation\n\n\ntrain_gen = train_datagen.flow_from_dataframe(dataframe = train_df, directory=train_path, x_col='filename', \n                                              y_col='class', target_size=(200,200), batch_size=64, \n                                               class_mode='binary')\nvalid_gen = test_datagen.flow_from_dataframe(dataframe = valid_df, directory=train_path, x_col='filename',\n                                             y_col='class', target_size=(200,200), batch_size=64, \n                                            class_mode='binary')\ntest_gen = test_datagen.flow_from_dataframe(dataframe = test_df, directory=test_path, x_col='filename', \n                                            y_col='class', target_size=(200,200), batch_size=64,\n                                             class_mode='binary')\n#class mode binary because we want the classifier to predict covid or not\n#target size (200,200) means we want the images to resized to 200*200","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:47:03.104558Z","iopub.execute_input":"2022-03-22T17:47:03.104960Z","iopub.status.idle":"2022-03-22T17:47:55.003680Z","shell.execute_reply.started":"2022-03-22T17:47:03.104928Z","shell.execute_reply":"2022-03-22T17:47:55.002750Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Found 16783 validated image filenames belonging to 2 classes.\nFound 1865 validated image filenames belonging to 2 classes.\nFound 400 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now start the transfer learning!","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nbase_model = tf.keras.applications.ResNet50V2(weights='imagenet', input_shape = (200,200,3),\n                                                     include_top=False)\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-22T17:50:44.728478Z","iopub.execute_input":"2022-03-22T17:50:44.728814Z","iopub.status.idle":"2022-03-22T17:50:49.113288Z","shell.execute_reply.started":"2022-03-22T17:50:44.728783Z","shell.execute_reply":"2022-03-22T17:50:49.112455Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n94674944/94668760 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model building","metadata":{}},{"cell_type":"code","source":"\n\nmodel = tf.keras.Sequential([\n    base_model, \n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h5\", save_best_only=True, verbose = 0),\n    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', verbose=1),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n]\n\nmodel.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001),\n              loss = 'binary_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:50:54.883507Z","iopub.execute_input":"2022-03-22T17:50:54.883830Z","iopub.status.idle":"2022-03-22T17:50:55.269512Z","shell.execute_reply.started":"2022-03-22T17:50:54.883800Z","shell.execute_reply":"2022-03-22T17:50:55.268716Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#CHANGE BACK TO 20 EPOCHS\nhistory = model.fit(train_gen, \n                    validation_data=valid_gen, epochs=5, \n                    callbacks=[callbacks])","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:52:30.686800Z","iopub.execute_input":"2022-03-22T17:52:30.687294Z","iopub.status.idle":"2022-03-22T18:25:41.797894Z","shell.execute_reply.started":"2022-03-22T17:52:30.687253Z","shell.execute_reply":"2022-03-22T18:25:41.796983Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/5\n263/263 [==============================] - 585s 2s/step - loss: 0.3261 - accuracy: 0.8745 - val_loss: 0.1856 - val_accuracy: 0.9351\nEpoch 2/5\n263/263 [==============================] - 350s 1s/step - loss: 0.1759 - accuracy: 0.9295 - val_loss: 0.1543 - val_accuracy: 0.9340\nEpoch 3/5\n263/263 [==============================] - 351s 1s/step - loss: 0.1572 - accuracy: 0.9331 - val_loss: 0.1567 - val_accuracy: 0.9362\nEpoch 4/5\n263/263 [==============================] - 351s 1s/step - loss: 0.1512 - accuracy: 0.9372 - val_loss: 0.1583 - val_accuracy: 0.9357\n\nEpoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\nEpoch 5/5\n263/263 [==============================] - 351s 1s/step - loss: 0.1439 - accuracy: 0.9400 - val_loss: 0.1604 - val_accuracy: 0.9346\nEpoch 00005: early stopping\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model evaluation and predictions","metadata":{}},{"cell_type":"code","source":"model.load_weights('./covid_classifier_model.h5')\nmodel.evaluate(test_gen)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T18:30:30.259015Z","iopub.execute_input":"2022-03-22T18:30:30.259439Z","iopub.status.idle":"2022-03-22T18:31:17.840497Z","shell.execute_reply.started":"2022-03-22T18:30:30.259396Z","shell.execute_reply":"2022-03-22T18:31:17.839715Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"7/7 [==============================] - 39s 6s/step - loss: 0.3970 - accuracy: 0.8350\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[0.39698219299316406, 0.8349999785423279]"},"metadata":{}}]},{"cell_type":"code","source":"preds = (model.predict(test_gen)>0.5).astype(\"int32\")\n\npreds","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-22T18:31:22.744582Z","iopub.execute_input":"2022-03-22T18:31:22.744919Z","iopub.status.idle":"2022-03-22T18:31:47.412607Z","shell.execute_reply.started":"2022-03-22T18:31:22.744868Z","shell.execute_reply":"2022-03-22T18:31:47.411786Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([[0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import resnet152\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torch.utils import data\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\n\n# ResNet Class\nclass ResNet(nn.Module):\n    def __init__(self):\n        super(ResNet, self).__init__()\n        \n        # define the resnet152\n        self.resnet = resnet152(pretrained=True)\n        \n        # isolate the feature blocks\n        self.features = nn.Sequential(self.resnet.conv1,\n                                      self.resnet.bn1,\n                                      nn.ReLU(),\n                                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n                                      self.resnet.layer1, \n                                      self.resnet.layer2, \n                                      self.resnet.layer3, \n                                      self.resnet.layer4)\n        \n        # average pooling layer\n        self.avgpool = self.resnet.avgpool\n        \n        # classifier\n        self.classifier = self.resnet.fc\n        \n        # gradient placeholder\n        self.gradient = None\n    \n    # hook for the gradients\n    def activations_hook(self, grad):\n        self.gradient = grad\n    \n    def get_gradient(self):\n        return self.gradient\n    \n    def get_activations(self, x):\n        return self.features(x)\n    \n    def forward(self, x):\n        \n        # extract the features\n        x = self.features(x)\n        \n        # register the hook\n        h = x.register_hook(self.activations_hook)\n        \n        # complete the forward pass\n        x = self.avgpool(x)\n        x = x.view((1, -1))\n        x = self.classifier(x)\n        \n        return x\n\n      \n# all the data transformation and loading\ntransform = transforms.Compose([transforms.Resize((224, 224)),\n                                transforms.ToTensor(), \n                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n#FIND DATASET FOLDER PATH\ndataset = ImageFolder(root='../input/covidx-cxr2', transform=transform)\ndataloader = data.DataLoader(dataset=dataset, batch_size=1, shuffle=False)\n\n# init the resnet\nresnet = ResNet()\n\n# set the evaluation mode\n_ = resnet.eval()\n\n# get the image\nimg, _ = next(iter(dataloader))\n\n# forward pass\npred = resnet(img)\n\npred.argmax(dim=1)  # prints tensor([2])\n\n# get the gradient of the output with respect to the parameters of the model\npred[:, 2].backward()\n\n# pull the gradients out of the model\ngradients = resnet.get_gradient()\n\n# pool the gradients across the channels\npooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n\n# get the activations of the last convolutional layer\nactivations = resnet.get_activations(img).detach()\n\n# weight the channels by corresponding gradients\nfor i in range(512):\n    activations[:, i, :, :] *= pooled_gradients[i]\n    \n# average the channels of the activations\nheatmap = torch.mean(activations, dim=1).squeeze()\n\n# relu on top of the heatmap\n# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\nheatmap = np.maximum(heatmap, 0)\n\n# normalize the heatmap\nheatmap /= torch.max(heatmap)\n\n# draw the heatmap\nplt.matshow(heatmap.squeeze())\n\n# make the heatmap to be a numpy array\nheatmap = heatmap.numpy()\n\n# interpolate the heatmap\nimg = cv2.imread(\"/kaggle/input/covidx-cxr2/train/\")\nheatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\nsuperimposed_img = heatmap * 0.4 + img\ncv2.imwrite('./gradcam/', superimposed_img)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T18:33:46.818564Z","iopub.execute_input":"2022-03-22T18:33:46.818918Z","iopub.status.idle":"2022-03-22T18:34:02.089944Z","shell.execute_reply.started":"2022-03-22T18:33:46.818865Z","shell.execute_reply":"2022-03-22T18:34:02.088207Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2a78403867b47f7afb1a1b1bcfd91f5"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-e26bedad95db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# interpolate the heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/covidx-cxr2/train/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplyColorMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLORMAP_JET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'shape'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 288x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAL+ElEQVR4nO3dX4xd9XXF8bU8M/bYBuNW/JGL3cJDZIVGKqYWbUSEWlAit0FpH/oQqkRKVImXNiJqpSjJS5X3CtGHKpJlSKlCgiIIUhW1NEghpUgNxDZOAduJIgRlrKSD5aTgof43Xn2YAx2coXPsOX+us78faeR7r6/P3rZnze+cc++520kE4JfburEbANA/gg4UQNCBAgg6UABBBwog6EABExV023ts/9D2j21/fuDaD9qet/3ikHWX1d9h+ynbh22/ZPvegevP2n7O9g+a+l8asn7Tw5Tt521/a+jaTf1XbL9g+5Dt/QPX3mr7UdtHbR+x/cFOtz8pr6PbnpL0I0kfljQn6fuS7k5yeKD6t0s6KekfknxgiJoX1N8maVuSg7avlHRA0h8P+Pe3pM1JTtqekfSMpHuTfG+I+k0Pfylpt6QtSe4aqu6y+q9I2p3k+Ai1H5L0b0n22V4vaVOSn3e1/Ula0W+V9OMkLyc5I+kRSX80VPEkT0s6MVS9Fer/JMnB5vabko5Iun7A+klysrk703wNtgrY3i7po5L2DVVzUti+StLtkh6QpCRnugy5NFlBv17Sa8vuz2nAb/RJYvsGSbskPTtw3SnbhyTNS3oyyZD175f0OUnnB6x5oUj6tu0Dtu8ZsO6Nkl6X9JXm0GWf7c1dFpikoEOS7SskPSbps0neGLJ2ksUkN0vaLulW24Mcwti+S9J8kgND1Pt/fCjJLZL+QNKfN4dzQ5iWdIukLyfZJWlBUqfnqCYp6Mck7Vh2f3vzWBnNsfFjkh5O8s2x+mh2G5+StGegkrdJ+lhzjPyIpDtsf3Wg2u9Icqz5dV7S41o6nBzCnKS5ZXtQj2op+J2ZpKB/X9L7bN/YnIz4uKR/HLmnwTQnwx6QdCTJfSPUv8b21ub2Ri2dFD06RO0kX0iyPckNWvp//06STwxR+222NzcnQdXsNn9E0iCvwCT5qaTXbO9sHrpTUqcnYae73NhaJDln+y8k/YukKUkPJnlpqPq2vy7p9yRdbXtO0l8neWCo+lpa1T4p6YXmOFmSvpjknwaqv03SQ82rH+skfSPJKC9zjeQ6SY8v/bzVtKSvJXliwPqfkfRws8i9LOnTXW58Yl5eA9CfSdp1B9ATgg4UQNCBAgg6UABBBwqYyKAP/PbDialNfer3VX8igy5pzH/sUf+jqU/9PjY6qUEH0KFe3jCz3hsyq0u/+OasTmtGGy69gU2zl1773Fuamd506bUlnds0del/9tSCpmfXduHS+fWX/mcXFxY0tbnTC6fK1c8als+11j934oQWFxZ84eO9vAV2Vpv1O76zj0234pt+c7TaknT85i2j1n/zxlHLy4u/8H02qEyN+27PxY3j1T923/0rPs6uO1AAQQcKIOhAAQQdKICgAwUQdKAAgg4UQNCBAgg6UABBBwpoFfQxhx8CWLtVg958/O/faWl6xU2S7rZ9U9+NAehOmxV91OGHANauTdAZfghc5jq7TLX5CJx7JGlWa7ueG0C32qzorYYfJtmbZHeS3Wv60AgAnWsT9NLDD4FfBqvuuo89/BDA2rU6Rm8meg411RNAx3hnHFAAQQcKIOhAAQQdKICgAwUQdKAAgg4UQNCBAgg6UABBBwroZZqqN85q3c7397HpVl7dc9VotSVp4+8eH7X+lnGHmepnb3CZ8mhmzq/4MCs6UABBBwog6EABBB0ogKADBRB0oACCDhRA0IECCDpQAEEHCiDoQAEEHSigzdjkB23P235xiIYAdK/Niv73kvb03AeAHq0a9CRPSzoxQC8AesIxOlBAZ0G3fY/t/bb3nzn3VlebBdCBzoK+fD76+mk+YQSYJOy6AwW0eXnt65L+XdJO23O2/6z/tgB0adUPh0xy9xCNAOgPu+5AAQQdKICgAwUQdKAAgg4UQNCBAgg6UABBBwog6EABBB0ooJf56JmyFq/Y0MemWzm189RotSXp5l99fdT6J06Pe/XgGwuzo9Y/vzju+jU1vThabXvlx1nRgQIIOlAAQQcKIOhAAQQdKICgAwUQdKAAgg4UQNCBAgg6UABBBwog6EABbQY47LD9lO3Dtl+yfe8QjQHoTpur185J+qskB21fKemA7SeTHO65NwAdaTMf/SdJDja335R0RNL1fTcGoDsXdYxu+wZJuyQ920s3AHrROui2r5D0mKTPJnljhd9/Zz762bMLXfYIYI1aBd32jJZC/nCSb670nOXz0WdmNnfZI4A1anPW3ZIekHQkyX39twSga21W9NskfVLSHbYPNV9/2HNfADrUZj76M5Le4yPnAFwOeGccUABBBwog6EABBB0ogKADBRB0oACCDhRA0IECCDpQAEEHCuhtPvqZq2b62HTLBsabTy1JL8xvG7X+r235hauIB/W+68adD/9fJ68ctf6Jn4139Way8uOs6EABBB0ogKADBRB0oACCDhRA0IECCDpQAEEHCiDoQAEEHSiAoAMFEHSggDaTWmZtP2f7B8189C8N0RiA7rS5eu20pDuSnGxmsD1j+5+TfK/n3gB0pM2klkg62dydab7e42I4AJOo7TTVKduHJM1LejIJ89GBy0iroCdZTHKzpO2SbrX9gQuf86756GeYjw5Mkos6657k55KekrRnhd/7v/no65mPDkySNmfdr7G9tbm9UdKHJR3tuS8AHWpz1n2bpIdsT2npB8M3knyr37YAdKnNWff/kLRrgF4A9IR3xgEFEHSgAIIOFEDQgQIIOlAAQQcKIOhAAQQdKICgAwUQdKCAXuajn5+23rq2l023kvPnR6stSYlHrX/8rU2j1l837l9fp86O970nSVNzs6PV9pmV125WdKAAgg4UQNCBAgg6UABBBwog6EABBB0ogKADBRB0oACCDhRA0IECCDpQQOugN4MWn7fN8AbgMnMxK/q9ko701QiA/rQdm7xd0kcl7eu3HQB9aLui3y/pc5LGvdAbwCVpM031LknzSQ6s8rx35qOfO8V8dGCStFnRb5P0MduvSHpE0h22v3rhk5bPR5+eZT46MElWDXqSLyTZnuQGSR+X9J0kn+i9MwCd4XV0oICL+hS9JN+V9N1eOgHQG1Z0oACCDhRA0IECCDpQAEEHCiDoQAEEHSiAoAMFEHSgAIIOFNDLIOmskxY39LHldtb998x4xSX96W8/M2r9L179w1HrP3f67Kj1/+bYnlHr7//PLaPVznss3azoQAEEHSiAoAMFEHSgAIIOFEDQgQIIOlAAQQcKIOhAAQQdKICgAwUQdKCAVhe1NOOY3pS0KOlckt19NgWgWxdz9drvJzneWycAesOuO1BA26BH0rdtH7B9z0pPeNfY5P9hbDIwSdruun8oyTHb10p60vbRJE8vf0KSvZL2StKma3ek4z4BrEGrFT3JsebXeUmPS7q1z6YAdGvVoNvebPvKt29L+oikF/tuDEB32uy6XyfpcdtvP/9rSZ7otSsAnVo16ElelvRbA/QCoCe8vAYUQNCBAgg6UABBBwog6EABBB0ogKADBRB0oACCDhRA0IECepmPvu6stGn+fB+bbuXkjnF/fs2d/pVR6x84fWbU+v+68P5R6x989ddHrb/1qEerPX9q5cdZ0YECCDpQAEEHCiDoQAEEHSiAoAMFEHSgAIIOFEDQgQIIOlAAQQcKaBV021ttP2r7qO0jtj/Yd2MAutP2opa/lfREkj+xvV7Sph57AtCxVYNu+ypJt0v6lCQlOSNp3MujAFyUNrvuN0p6XdJXbD9ve18zgw3AZaJN0Kcl3SLpy0l2SVqQ9PkLn7R8PvrZ0yc7bhPAWrQJ+pykuSTPNvcf1VLw3yXJ3iS7k+ye2XBFlz0CWKNVg57kp5Jes72zeehOSYd77QpAp9qedf+MpIebM+4vS/p0fy0B6FqroCc5JGl3v60A6AvvjAMKIOhAAQQdKICgAwUQdKAAgg4UQNCBAgg6UABBBwog6EABBB0owEm636j9uqRX17CJqyUd76idy6k29am/1vq/keSaCx/sJehrZXt/klEuohmzNvWp31d9dt2BAgg6UMCkBn1v0drUp34v9SfyGB1AtyZ1RQfQIYIOFEDQgQIIOlAAQQcK+F+PIxxgvMz+UgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}